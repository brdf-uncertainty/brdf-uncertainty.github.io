<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description"
    content="Project page for Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture using Frequency Domain Analysis">
  <meta property="og:title"
    content="Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture using Frequency Domain Analysis" />
  <meta property="og:description"
    content="Relightable object acquisition is a key challenge in simplifying digital asset creation. We approach this problem by leveraging frequency domain analysis, enabling fast optimization and a measure of uncertainty based on entropy." />
  <meta property="og:url" content="https://brdf-uncertainty.github.io" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title"
    content="Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture using Frequency Domain Analysis">
  <meta name="twitter:description"
    content="Relightable object acquisition is a key challenge in simplifying digital asset creation. We approach this problem by leveraging frequency domain analysis, enabling fast optimization and a measure of uncertainty based on entropy.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords"
    content="BRDF, SVBRDF, relighting, inverse rendering, differentiable rendering, spherical harmonics, acquisition, material, appearance">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture using Frequency Domain Analysis</title>

  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="stylesheet" href="https://use.typekit.net/fiu3sit.css">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script defer data-domain="brdf-uncertainty.github.io" src="https://plausible.io/js/script.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-left">
            <h1 class="title is-2 publication-title">Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture
              using Frequency Domain Analysis</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Anonymous authors,</span>

              <div class="is-size-5 publication-authors">
                <span class="author-block">ArXiv 2024</span>
              </div>
            </div>
            <div class="column has-text-left">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-folder"></i>
                    </span>
                    <span>Supplementary (to be released, 257MB)</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="#" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (to be released)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser image-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="static/images/teaser.jpg" alt="Overview image." />
        <h2 class="subtitle has-text-left">
          We present fast and uncertainty-aware multi-view material acquisition for objects captured in uncontrolled setups.
          We propose to build upon and extend the <b>signal processing framework for inverse rendering</b> by Ramamoorthi and
          Hanrahan (2001): we improve the model with <b>shadowing and masking</b> and propose a lightweight objective function
          for BRDF fitting using spherical harmonics power spectra (center). We then use this approximation to
          provide a measure of <b>uncertainty relying on statistical entropy</b>. We show that our material estimation is
          significantly faster than previous work and achieves similar or better results (right).
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser image -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-left">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-left">
            <p>
              Relightable object acquisition is a key challenge in simplifying digital asset creation.
              Complete reconstruction of an object typically requires capturing hundreds to thousands of photographs
              under controlled illumination, with specialized equipment.
              The recent progress in differentiable rendering improved the quality and accessibility of inverse
              rendering optimization.
              Nevertheless, under uncontrolled illumination and unstructured viewpoints, there is no guarantee that the
              observations contain enough information to reconstruct the appearance properties of the captured object.
            </p>
            <p>
              We thus propose to consider the acquisition process from a signal-processing perspective.
              Given an object's geometry and a lighting environment, we estimate the properties of the materials on the
              object's surface in seconds.
              We do so by leveraging frequency domain analysis, considering the recovery of material properties as a
              deconvolution, enabling fast error estimation.
              We then quantify the uncertainty of the estimation, based on the available data, highlighting the areas
              for which priors or additional samples would be required for improved acquisition quality.
              We compare our approach to previous work and quantitatively evaluate our results, showing similar quality
              as previous work in a fraction of the time, and providing key information about the certainty of the
              results.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  
   <section class="section">
    <!-- Relighting -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <h2 class="title is-3">Relighting results</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-object1">
            <div class="columns">
              <div class="column">
                <h2 class="subtitle">Ours, <b>5.27</b>s</h2>
                <video poster="" id="teapot_ours" autoplay muted playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/gnome_scene003/video/sh/vid.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column">
                <h2 class="subtitle">Ours + Mitsuba, <b>19.87</b>s</h2>
                <video poster="" id="teapot_oursplus" autoplay muted playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/gnome_scene003/video/oursplusmitsuba/vid.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column">
                <h2 class="subtitle">Mitsuba, <b>69.96</b>s</h2>
                <video poster="" id="teapot_mitsuba" autoplay muted playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/gnome_scene003/video/mitsuba/vid.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column">
                <h2 class="subtitle">NVDiffRec, <b>142.14</b>s</h2>
                <video poster="" id="teapot_nv" autoplay muted playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/gnome_scene003/video/nvdiffrec/vid.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>
          <div class="item item-object2">
            <div class="columns">
              <div class="column">
                <h2 class="subtitle">Ours, <b>5.27</b>s</h2>
                <video poster="" id="teapot_ours" autoplay muted playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/cactus_scene005/video/sh/vid.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column">
                <h2 class="subtitle">Ours + Mitsuba, <b>19.87</b>s</h2>
                <video poster="" id="teapot_oursplus" autoplay muted playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/cactus_scene005/video/oursplusmitsuba/vid.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column">
                <h2 class="subtitle">Mitsuba, <b>69.96</b>s</h2>
                <video poster="" id="teapot_mitsuba" autoplay muted playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/cactus_scene005/video/mitsuba/vid.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column">
                <h2 class="subtitle">NVDiffRec, <b>142.14</b>s</h2>
                <video poster="" id="teapot_nv" autoplay muted playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/cactus_scene005/video/nvdiffrec/vid.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>
          <div class="item item-object3">
            <div class="columns">
              <div class="column">
                <h2 class="subtitle">Ours, <b>5.27</b>s</h2>
                <video poster="" id="teapot_ours" autoplay mute playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/teapot_scene001/video/sh/vid.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column">
                <h2 class="subtitle">Ours + Mitsuba, <b>19.87</b>s</h2>
                <video poster="" id="teapot_oursplus" autoplay muted playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/teapot_scene001/video/oursplusmitsuba/vid.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column">
                <h2 class="subtitle">Mitsuba, <b>69.96</b>s</h2>
                <video poster="" id="teapot_mitsuba" autoplay muted playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/teapot_scene001/video/mitsuba/vid.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column">
                <h2 class="subtitle">NVDiffRec, <b>142.14</b>s</h2>
                <video poster="" id="teapot_nv" autoplay muted playinline loop width="100%">
                  <!-- Your video file here -->
                  <source src="static/video/teapot_scene001/video/nvdiffrec/vid.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>

        </div>
        <p>We optimize a PBR texture (base color, metallicity, roughness) on multi-view captures from <a
            href="https://stanfordorb.github.io" target="_blank">Stanford ORB</a> and relight the resulting object in Blender.
            More results in the supplemental material and the paper.
        </p>
      </div>
    </div>
  </section>
  <!-- End relighting -->

  <!-- Uncertainty -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="content">
          <h2 class="title is-3">Uncertainty results</h2>
          <p>We show that our formulation for uncertainty using entropy matches with errors resulting from an
            optimization with Mitsuba.</p>
          <br/>
          <img src="static/images/uncertainty.png" alt="Uncertainty." />
          <br/><br/>
          <p>
            On the right, we show the average estimation error followed by our entropy estimation. We observe that low
            entropy is indicative of lower error, suggesting that it captures the sufficiency of information in the
            input signal. On the dice example (top row), the `one'-face is lit less than other faces and we observe
            highlights with lower intensity, leading to higher entropy. While we still recover the white albedo
            correctly, the estimation of roughness and metallicity for the dot has a high error. Similarly, the inside
            and lower parts of the doughnut are less observed and not lit by strong light sources. Again, entropy is
            high in regions of high error (especially in metallicity). The triceratops collar is down-facing and not
            well-lit and our entropy captures the lack of observation that leads to high error in the metallicity part.
          </p>
        </div>
      </div>
    </div>
  </section>
  <!-- End uncertainty -->
   </section>

  <!--Method overview -->
  <section class="section hero is-light is-small" id="method">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-left">
        <h2 class="title is-3">Method overview</h2>
        
      </div>
    </div>
  </section>
  <!--End method overview -->

  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>Coming soon</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow from this website, we just ask that you link back to this page in the footer. <br>
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
                target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <script>
    bulmaCarousel.attach('#results-carousel', {
      autoplay: true,
      autoplaySpeed: 6000,
      loop: true
    });
  </script>
</body>

</html>